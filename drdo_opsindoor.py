# -*- coding: utf-8 -*-
"""DRDO-OPSINDOOR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15f7eejeZfesh3tVDYaeGMAIH8HjvRU-V

***DRDO Python Projects for Cyber Defense after Operation Sindoor***

Image Processing for Surveillance
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

video_path = '/content/surveillance_video.mp4.mov'
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    raise FileNotFoundError(f"Video file not found: {video_path}")

# Background subtractor with shadow detection disabled (better for security)
fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=False)

# Kernel for noise removal
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Preprocessing: Gaussian Blur (reduces noise)
    blurred = cv2.GaussianBlur(frame, (5, 5), 0)

    # Apply background subtraction
    fgmask = fgbg.apply(blurred)

    # Post-processing: Remove noise (morphological ops)
    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)

    # Find contours of moving objects (for tracking)
    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Draw bounding boxes around detected objects
    for contour in contours:
        if cv2.contourArea(contour) > 500:  # Filter small noises
            x, y, w, h = cv2.boundingRect(contour)
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Display results
    cv2_imshow(frame)
    cv2_imshow(fgmask)

    if cv2.waitKey(30) & 0xFF == 27:  # Exit on 'Esc'
        break

cap.release()
cv2.destroyAllWindows()

"""Maintenance model using machine learning to predict equipment failures based on historical data."""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Load dataset
data = pd.read_csv('equipment_data.csv')

# Preprocess data
# Drop non-numeric columns and the target variable for features
X = data.drop(['timestamp', 'machine_id', 'failure_mode', 'failure'], axis=1)
y = data['failure']

# Convert categorical features to numerical using one-hot encoding
X = pd.get_dummies(X, columns=['machine_type'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
print(classification_report(y_test, y_pred))

"""NLP model to analyze text data for potential threats or suspicious activities."""

# Import necessary libraries
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load dataset
data = pd.read_csv('threat_data.csv')  # Assume this has 'text' and 'label' columns

# Preprocess data
X = data['text']
y = data['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize text data
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

# Train a Naive Bayes model
model = MultinomialNB()
model.fit(X_train_vectorized, y_train)

# Make predictions
y_pred = model.predict(X_test_vectorized)

# Evaluate the model
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')

"""Drone Path Planning"""

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from scipy.spatial import distance

# Define the grid and obstacles
grid_size = (10, 10)
obstacles = [(3, 3), (4, 4), (5, 5)]

# Simple A* pathfinding algorithm
def heuristic(a, b):
    return distance.euclidean(a, b)

def astar(start, goal):
    open_set = {start}
    came_from = {}
    g_score = {start: 0}
    f_score = {start: heuristic(start, goal)}

    while open_set:
        current = min(open_set, key=lambda x: f_score.get(x, float('inf')))
        if current == goal:
            return reconstruct_path(came_from, current)

        open_set.remove(current)
        for neighbor in get_neighbors(current):
            if neighbor in obstacles:
                continue
            tentative_g_score = g_score[current] + 1
            if tentative_g_score < g_score.get(neighbor, float('inf')):
                came_from[neighbor] = current
                g_score[neighbor] = tentative_g_score
                f_score[neighbor] = g_score[neighbor] + heuristic(neighbor, goal)
                open_set.add(neighbor)

    return []

def get_neighbors(node):
    neighbors = []
    for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
        neighbor = (node[0] + dx, node[1] + dy)
        if 0 <= neighbor[0] < grid_size[0] and 0 <= neighbor[1] < grid_size[1]:
            neighbors.append(neighbor)
    return neighbors

def reconstruct_path(came_from, current):
    total_path = [current]
    while current in came_from:
        current = came_from[current]
        total_path.append(current)
    return total_path[::-1]

# Example usage
start = (0, 0)
goal = (7, 7)
path = astar(start, goal)
print("Path:", path)

""" Cybersecurity Threat Analysis Dashboard"""

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load cybersecurity threat data
data = pd.read_csv('cybersecurity_data.csv')

# Visualize the data
plt.figure(figsize=(10, 6))
sns.countplot(data=data, x='threat_type', hue='severity')
plt.title('Cybersecurity Threat Analysis')
plt.xticks(rotation=45)
plt.show()